{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlk888/Yandex_ML-contest3_25s/blob/main/homeworks/hw01_classification/02_hw_fmnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jUZ7kCOkH9ad"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        params = params.rstrip(\")\")\n",
        "        layer_info[\"type\"] = layer_name.strip()\n",
        "        param_dict = {}\n",
        "        for param in params.split(\", \"):\n",
        "            if \"=\" in param:\n",
        "                key, value = param.split(\"=\")\n",
        "                param_dict[key.strip()] = eval(value.strip())\n",
        "            else:\n",
        "                param_dict[param.strip()] = None\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eMTRpZgdH9ad"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDrV0BJIH9ae"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p7f8d7AAH9ae",
        "outputId": "89cf136d-b4b3-40dc-9c70-069a49da4d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-09 10:53:22--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-09 10:53:22--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-04-09 10:53:22 (255 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zQWqvLoxH9ae"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pwyJN-B-H9af"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aYcL28OsgSq8",
        "outputId": "87442953-5d94-4356-f84b-9669f9cdcab6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 8')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = None\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # Глобальный пулинг\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // 8, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // 8, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        # Глобальный пулинг → веса внимания\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        # Применение весов внимания к исходной карте признаков\n",
        "        return x * y\n",
        "\n",
        "class FashionMNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Свёрточные слои\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 28x28 → 28x28\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(2)  # 28x28 → 14x14\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 14x14 → 14x14\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(2)  # 14x14 → 7x7\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 7x7 → 7x7\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Attention слой\n",
        "        self.attention = AttentionLayer(128)\n",
        "\n",
        "        # Полносвязные слои\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 256)  # 128 фильтров * 7x7\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.attention(x)  # Применение внимания\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Создание экземпляра модели\n",
        "model_task_1 = FashionMNISTModel()\n",
        "#for m in model_task_1.modules():\n",
        "#    if isinstance(m, nn.Conv2d):\n",
        "#        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "d257f2b3-5a17-43ef-c398-2ac69ec778bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModel(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (attention): AttentionLayer(\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=128, out_features=16, bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Linear(in_features=16, out_features=128, bias=False)\n",
              "      (3): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=6272, out_features=256, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "d1009160-2901-4593-a20a-be0bec3e0734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5315bde2-8183-4b27-cce1-871ff8e8ddc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30: Train Loss: 0.3884, Test Accuracy: 89.46%, LR: 0.000500\n",
            "Epoch 2/30: Train Loss: 0.2672, Test Accuracy: 91.25%, LR: 0.000500\n",
            "Epoch 3/30: Train Loss: 0.2268, Test Accuracy: 91.09%, LR: 0.000500\n",
            "Epoch 4/30: Train Loss: 0.1991, Test Accuracy: 91.76%, LR: 0.000500\n",
            "Epoch 5/30: Train Loss: 0.1759, Test Accuracy: 92.09%, LR: 0.000500\n",
            "Epoch 6/30: Train Loss: 0.1546, Test Accuracy: 92.17%, LR: 0.000500\n",
            "Epoch 7/30: Train Loss: 0.1367, Test Accuracy: 92.55%, LR: 0.000500\n",
            "Epoch 8/30: Train Loss: 0.1204, Test Accuracy: 91.70%, LR: 0.000500\n",
            "Epoch 9/30: Train Loss: 0.1035, Test Accuracy: 92.72%, LR: 0.000500\n",
            "Epoch 10/30: Train Loss: 0.0905, Test Accuracy: 92.45%, LR: 0.000500\n",
            "Epoch 11/30: Train Loss: 0.0802, Test Accuracy: 92.58%, LR: 0.000500\n",
            "Epoch 12/30: Train Loss: 0.0726, Test Accuracy: 92.72%, LR: 0.000500\n",
            "Epoch 13/30: Train Loss: 0.0644, Test Accuracy: 92.38%, LR: 0.000250\n",
            "Epoch 14/30: Train Loss: 0.0374, Test Accuracy: 92.95%, LR: 0.000250\n",
            "Epoch 15/30: Train Loss: 0.0296, Test Accuracy: 93.22%, LR: 0.000250\n",
            "Epoch 16/30: Train Loss: 0.0258, Test Accuracy: 92.97%, LR: 0.000250\n",
            "Epoch 17/30: Train Loss: 0.0226, Test Accuracy: 92.83%, LR: 0.000250\n",
            "Epoch 18/30: Train Loss: 0.0216, Test Accuracy: 92.72%, LR: 0.000250\n",
            "Epoch 19/30: Train Loss: 0.0184, Test Accuracy: 92.92%, LR: 0.000125\n",
            "Epoch 20/30: Train Loss: 0.0106, Test Accuracy: 93.23%, LR: 0.000125\n",
            "Epoch 21/30: Train Loss: 0.0094, Test Accuracy: 93.16%, LR: 0.000125\n",
            "Epoch 22/30: Train Loss: 0.0085, Test Accuracy: 93.19%, LR: 0.000125\n",
            "Epoch 23/30: Train Loss: 0.0074, Test Accuracy: 93.22%, LR: 0.000125\n",
            "Epoch 24/30: Train Loss: 0.0066, Test Accuracy: 93.29%, LR: 0.000125\n",
            "Epoch 25/30: Train Loss: 0.0062, Test Accuracy: 93.18%, LR: 0.000125\n",
            "Epoch 26/30: Train Loss: 0.0062, Test Accuracy: 93.15%, LR: 0.000125\n",
            "Epoch 27/30: Train Loss: 0.0058, Test Accuracy: 93.15%, LR: 0.000125\n",
            "Epoch 28/30: Train Loss: 0.0061, Test Accuracy: 93.32%, LR: 0.000125\n",
            "Epoch 29/30: Train Loss: 0.0054, Test Accuracy: 93.16%, LR: 0.000125\n",
            "Epoch 30/30: Train Loss: 0.0054, Test Accuracy: 93.03%, LR: 0.000125\n",
            "Обучение завершено. Лучшая Test Accuracy: 93.32%\n"
          ]
        }
      ],
      "source": [
        "# Оптимизатор: AdamW с начальным LR=0.0005 и weight_decay=1e-4 для L2-регуляризации\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.0005)\n",
        "\n",
        "# Scheduler: ReduceLROnPlateau для динамического изменения LR\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# Функция потерь: CrossEntropyLoss для задачи классификации\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Количество эпох\n",
        "num_epochs = 30\n",
        "\n",
        "# Переменные для ранней остановки\n",
        "best_test_acc = 0.0\n",
        "patience_counter = 0\n",
        "patience_limit = 5  # Остановка после 5 эпох без улучшений\n",
        "\n",
        "# Цикл обучения\n",
        "for epoch in range(num_epochs):\n",
        "    # Режим обучения\n",
        "    model_task_1.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in train_data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Обнуляем градиенты\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Прямой проход\n",
        "        outputs = model_task_1(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Обратный проход и шаг оптимизации\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Суммируем Train Loss\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Средний Train Loss за эпоху\n",
        "    train_loss /= len(train_data_loader.dataset)\n",
        "\n",
        "    # Оценка на тестовом наборе\n",
        "    model_task_1.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_task_1(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Test Accuracy\n",
        "    test_acc = 100 * correct / total\n",
        "\n",
        "    # Обновляем scheduler на основе Test Accuracy\n",
        "    scheduler.step(test_acc)\n",
        "\n",
        "    # Текущий LR\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Вывод метрик\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Accuracy: {test_acc:.2f}%, LR: {current_lr:.6f}\")\n",
        "\n",
        "    # Сохранение лучшей модели и ранняя остановка\n",
        "    if test_acc > best_test_acc:\n",
        "        best_test_acc = test_acc\n",
        "        torch.save(model_task_1.state_dict(), 'best_model.pth')\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience_limit:\n",
        "            print(f\"Ранняя остановка на эпохе {epoch+1}. Лучшая Test Accuracy: {best_test_acc:.2f}%\")\n",
        "            break\n",
        "\n",
        "if patience_counter < patience_limit:\n",
        "    print(f\"Обучение завершено. Лучшая Test Accuracy: {best_test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "5e33192e-115c-459b-8e09-db0f9bba53f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.99992\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "c0351949-396c-4826-ca37-39e6a88204a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9303\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAIrURCEgSq_",
        "outputId": "ecaec63d-c4bd-44fa-e556-6e95a510c022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Test Accuracy: 93.03%\n",
            "\n",
            "Class-wise Accuracy:\n",
            "T-shirt/top    : 89.40%\n",
            "Trouser        : 98.60%\n",
            "Pullover       : 90.80%\n",
            "Dress          : 93.30%\n",
            "Coat           : 90.60%\n",
            "Sandal         : 98.60%\n",
            "Shirt          : 75.80%\n",
            "Sneaker        : 97.90%\n",
            "Bag            : 98.10%\n",
            "Ankle boot     : 97.20%\n"
          ]
        }
      ],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\"\n",
        "\n",
        "def class_wise_accuracy(model, test_loader, num_classes=10):\n",
        "    model.eval()\n",
        "    correct_pred = {class_idx: 0 for class_idx in range(num_classes)}\n",
        "    total_pred = {class_idx: 0 for class_idx in range(num_classes)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            # Update counts for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                class_idx = label.item()\n",
        "                total_pred[class_idx] += 1\n",
        "                if prediction == label:\n",
        "                    correct_pred[class_idx] += 1\n",
        "\n",
        "    # Calculate accuracy for each class\n",
        "    class_acc = {}\n",
        "    for class_idx in range(num_classes):\n",
        "        if total_pred[class_idx] > 0:\n",
        "            acc = 100 * correct_pred[class_idx] / total_pred[class_idx]\n",
        "            class_acc[class_idx] = acc\n",
        "        else:\n",
        "            class_acc[class_idx] = 0.0  # Handle case with zero samples\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    total_correct = sum(correct_pred.values())\n",
        "    total_samples = sum(total_pred.values())\n",
        "    overall_acc = 100 * total_correct / total_samples\n",
        "\n",
        "    return class_acc, overall_acc\n",
        "\n",
        "class_acc, overall_acc = class_wise_accuracy(model_task_1, test_data_loader)\n",
        "\n",
        "# Вывод результатов\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(f\"Overall Test Accuracy: {overall_acc:.2f}%\")\n",
        "print(\"\\nClass-wise Accuracy:\")\n",
        "for idx, name in enumerate(class_names):\n",
        "    print(f\"{name:15}: {class_acc[idx]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVpYzE23H9ah"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "0sb8aZenH9ah",
        "outputId": "39c63119-e085-42df-9cc7-8af694df136b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDthBDWeH9ah"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}