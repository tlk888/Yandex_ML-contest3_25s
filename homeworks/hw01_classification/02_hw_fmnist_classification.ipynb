{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlk888/Yandex_ML-contest3_25s/blob/main/homeworks/hw01_classification/02_hw_fmnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jUZ7kCOkH9ad"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        params = params.rstrip(\")\")\n",
        "        layer_info[\"type\"] = layer_name.strip()\n",
        "        param_dict = {}\n",
        "        for param in params.split(\", \"):\n",
        "            if \"=\" in param:\n",
        "                key, value = param.split(\"=\")\n",
        "                param_dict[key.strip()] = eval(value.strip())\n",
        "            else:\n",
        "                param_dict[param.strip()] = None\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eMTRpZgdH9ad"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDrV0BJIH9ae"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p7f8d7AAH9ae",
        "outputId": "8f1283ba-167a-43a0-8a31-67e687fb9b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-08 20:40:54--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-08 20:40:55--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-04-08 20:40:55 (80.5 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zQWqvLoxH9ae"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pwyJN-B-H9af"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aYcL28OsgSq8",
        "outputId": "d3c3422a-cd69-4f24-ff28-02c29dce3eb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 5')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = None\n",
        "\n",
        "class WSConv2d(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
        "        nn.init.kaiming_normal_(self.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weight = self.weight\n",
        "        weight_mean = weight.mean(dim=(1,2,3), keepdim=True)\n",
        "        weight_std = weight.std(dim=(1,2,3), keepdim=True)\n",
        "        standardized_weight = (weight - weight_mean) / (weight_std + 1e-5)\n",
        "        return F.conv2d(\n",
        "            x, standardized_weight, self.bias,\n",
        "            self.stride, self.padding, self.dilation, self.groups\n",
        "        )\n",
        "\n",
        "# Creating model instance\n",
        "class FashionMNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            WSConv2d(1, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            WSConv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model_task_1 = FashionMNISTModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "85c94cc7-421e-4b0c-a5f4-39b80329df1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModel(\n",
              "  (net): Sequential(\n",
              "    (0): WSConv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): WSConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    (7): Linear(in_features=3136, out_features=128, bias=True)\n",
              "    (8): ReLU()\n",
              "    (9): Dropout(p=0.5, inplace=False)\n",
              "    (10): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "3cf7efbf-b79f-4210-c6ae-a496fa178b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4e6617-b6ce-41de-9e17-068461fa0fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "Train Loss: 0.6281 | Test Accuracy: 0.8622 | LR: 5.00e-05\n",
            "\n",
            "Epoch 2/30\n",
            "Train Loss: 0.4174 | Test Accuracy: 0.8792 | LR: 5.00e-05\n",
            "\n",
            "Epoch 3/30\n",
            "Train Loss: 0.3636 | Test Accuracy: 0.8887 | LR: 5.00e-05\n",
            "\n",
            "Epoch 4/30\n",
            "Train Loss: 0.3266 | Test Accuracy: 0.8940 | LR: 5.00e-05\n",
            "\n",
            "Epoch 5/30\n",
            "Train Loss: 0.3049 | Test Accuracy: 0.8979 | LR: 5.00e-05\n",
            "\n",
            "Epoch 6/30\n",
            "Train Loss: 0.2821 | Test Accuracy: 0.9020 | LR: 5.00e-05\n",
            "\n",
            "Epoch 7/30\n",
            "Train Loss: 0.2653 | Test Accuracy: 0.9046 | LR: 5.00e-05\n",
            "\n",
            "Epoch 8/30\n",
            "Train Loss: 0.2540 | Test Accuracy: 0.9084 | LR: 5.00e-05\n",
            "\n",
            "Epoch 9/30\n",
            "Train Loss: 0.2422 | Test Accuracy: 0.9056 | LR: 5.00e-05\n",
            "\n",
            "Epoch 10/30\n",
            "Train Loss: 0.2300 | Test Accuracy: 0.9069 | LR: 5.00e-05\n",
            "\n",
            "Epoch 11/30\n",
            "Train Loss: 0.2211 | Test Accuracy: 0.9091 | LR: 5.00e-05\n",
            "\n",
            "Epoch 12/30\n",
            "Train Loss: 0.2117 | Test Accuracy: 0.9142 | LR: 5.00e-05\n",
            "\n",
            "Epoch 13/30\n",
            "Train Loss: 0.2030 | Test Accuracy: 0.9137 | LR: 5.00e-05\n",
            "\n",
            "Epoch 14/30\n",
            "Train Loss: 0.1963 | Test Accuracy: 0.9149 | LR: 5.00e-05\n",
            "\n",
            "Epoch 15/30\n",
            "Train Loss: 0.1888 | Test Accuracy: 0.9184 | LR: 5.00e-05\n",
            "\n",
            "Epoch 16/30\n",
            "Train Loss: 0.1802 | Test Accuracy: 0.9175 | LR: 5.00e-05\n",
            "\n",
            "Epoch 17/30\n",
            "Train Loss: 0.1745 | Test Accuracy: 0.9150 | LR: 5.00e-05\n",
            "\n",
            "Learning rate reduced to 1.00e-05\n",
            "\n",
            "Epoch 18/30\n",
            "Train Loss: 0.1696 | Test Accuracy: 0.9154 | LR: 1.00e-05\n",
            "\n",
            "Epoch 19/30\n",
            "Train Loss: 0.1443 | Test Accuracy: 0.9196 | LR: 1.00e-05\n",
            "\n",
            "Epoch 20/30\n",
            "Train Loss: 0.1374 | Test Accuracy: 0.9206 | LR: 1.00e-05\n",
            "\n",
            "Epoch 21/30\n",
            "Train Loss: 0.1346 | Test Accuracy: 0.9204 | LR: 1.00e-05\n",
            "\n",
            "Epoch 22/30\n",
            "Train Loss: 0.1338 | Test Accuracy: 0.9236 | LR: 1.00e-05\n",
            "\n",
            "Epoch 23/30\n",
            "Train Loss: 0.1309 | Test Accuracy: 0.9207 | LR: 1.00e-05\n",
            "\n",
            "Epoch 24/30\n",
            "Train Loss: 0.1279 | Test Accuracy: 0.9223 | LR: 1.00e-05\n",
            "\n",
            "Learning rate reduced to 2.00e-06\n",
            "\n",
            "Epoch 25/30\n",
            "Train Loss: 0.1260 | Test Accuracy: 0.9216 | LR: 2.00e-06\n",
            "\n",
            "Epoch 26/30\n",
            "Train Loss: 0.1204 | Test Accuracy: 0.9225 | LR: 2.00e-06\n",
            "\n",
            "Epoch 27/30\n",
            "Train Loss: 0.1211 | Test Accuracy: 0.9220 | LR: 2.00e-06\n",
            "\n",
            "Early stopping triggered\n",
            "\n",
            "Final Test Accuracy: 0.9236\n"
          ]
        }
      ],
      "source": [
        "# Гиперпараметры\n",
        "LEARNING_RATE = 0.00005\n",
        "EPOCHS = 30\n",
        "PATIENCE = 5\n",
        "\n",
        "# Инициализация компонентов обучения\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=LEARNING_RATE, weight_decay=3e-4)\n",
        "#optimizer = torch.optim.SGD(\n",
        "#    model_task_1.parameters(),\n",
        "#    lr=LEARNING_RATE,         # Начальный learning rate\n",
        "#    momentum=0.9,     # Добавляем momentum\n",
        "#    nesterov=True,    # Включаем Nesterov acceleration\n",
        "#    weight_decay=5e-4\n",
        "#)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.2, min_lr=1e-6)\n",
        "#scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
        "#    optimizer,\n",
        "#    base_lr=0.00005,\n",
        "#    max_lr=0.01,\n",
        "#    step_size_up=1000,\n",
        "#    mode='triangular2'\n",
        "#)\n",
        "\n",
        "best_accuracy = 0.0\n",
        "no_improve = 0\n",
        "prev_lr = LEARNING_RATE  # Для отслеживания изменения LR\n",
        "\n",
        "# Цикл обучения\n",
        "for epoch in range(EPOCHS):\n",
        "    model_task_1.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_task_1(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Валидация\n",
        "    model_task_1.eval()\n",
        "    test_accuracy = get_accuracy(model_task_1, test_data_loader)\n",
        "    epoch_loss = running_loss / len(train_data_loader.dataset)\n",
        "\n",
        "    # Обновление LR с ручным отслеживанием\n",
        "    scheduler.step(test_accuracy)\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Вывод информации об изменении LR\n",
        "    if current_lr != prev_lr:\n",
        "        print(f\"\\nLearning rate reduced to {current_lr:.2e}\")\n",
        "        prev_lr = current_lr\n",
        "\n",
        "    # Логирование\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    print(f\"Train Loss: {epoch_loss:.4f} | Test Accuracy: {test_accuracy:.4f} | LR: {current_lr:.2e}\")\n",
        "\n",
        "    # Ранняя остановка и сохранение модели\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        torch.save(model_task_1.state_dict(), \"best_model.pth\")\n",
        "        no_improve = 0\n",
        "        if test_accuracy >= 0.985:\n",
        "            print(\"\\nTarget accuracy reached!\")\n",
        "            break\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve == PATIENCE:\n",
        "            print(\"\\nEarly stopping triggered\")\n",
        "            break\n",
        "\n",
        "# Загрузка лучшей модели\n",
        "model_task_1.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "final_accuracy = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"\\nFinal Test Accuracy: {final_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "5a50df7d-6fde-4651-9187-638d2e944e74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.96877\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "8d4cbbf3-a50f-432d-eca3-3d24b5655f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9236\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAIrURCEgSq_",
        "outputId": "73783426-a306-448d-e4bb-4ca71c357d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Test Accuracy: 92.36%\n",
            "\n",
            "Class-wise Accuracy:\n",
            "T-shirt/top    : 89.10%\n",
            "Trouser        : 98.60%\n",
            "Pullover       : 88.00%\n",
            "Dress          : 92.40%\n",
            "Coat           : 90.10%\n",
            "Sandal         : 98.50%\n",
            "Shirt          : 74.60%\n",
            "Sneaker        : 97.70%\n",
            "Bag            : 98.50%\n",
            "Ankle boot     : 96.10%\n"
          ]
        }
      ],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\"\n",
        "\n",
        "def class_wise_accuracy(model, test_loader, num_classes=10):\n",
        "    model.eval()\n",
        "    correct_pred = {class_idx: 0 for class_idx in range(num_classes)}\n",
        "    total_pred = {class_idx: 0 for class_idx in range(num_classes)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            # Update counts for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                class_idx = label.item()\n",
        "                total_pred[class_idx] += 1\n",
        "                if prediction == label:\n",
        "                    correct_pred[class_idx] += 1\n",
        "\n",
        "    # Calculate accuracy for each class\n",
        "    class_acc = {}\n",
        "    for class_idx in range(num_classes):\n",
        "        if total_pred[class_idx] > 0:\n",
        "            acc = 100 * correct_pred[class_idx] / total_pred[class_idx]\n",
        "            class_acc[class_idx] = acc\n",
        "        else:\n",
        "            class_acc[class_idx] = 0.0  # Handle case with zero samples\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    total_correct = sum(correct_pred.values())\n",
        "    total_samples = sum(total_pred.values())\n",
        "    overall_acc = 100 * total_correct / total_samples\n",
        "\n",
        "    return class_acc, overall_acc\n",
        "\n",
        "class_acc, overall_acc = class_wise_accuracy(model_task_1, test_data_loader)\n",
        "\n",
        "# Вывод результатов\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(f\"Overall Test Accuracy: {overall_acc:.2f}%\")\n",
        "print(\"\\nClass-wise Accuracy:\")\n",
        "for idx, name in enumerate(class_names):\n",
        "    print(f\"{name:15}: {class_acc[idx]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVpYzE23H9ah"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0sb8aZenH9ah",
        "outputId": "34c7de02-2d87-4720-b6e7-a1b378890e83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import ast\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        parts = layer_str.split(\"(\", 1)\n",
        "        layer_name = parts[0].strip()\n",
        "        layer_info[\"type\"] = layer_name\n",
        "\n",
        "        if len(parts) == 1:\n",
        "            layer_info[\"parameters\"] = {}\n",
        "            return layer_info\n",
        "\n",
        "        params_str = parts[1].rstrip(\")\")\n",
        "        param_dict = {}\n",
        "        current_param = []\n",
        "        in_brackets = 0\n",
        "\n",
        "        for char in params_str + \",\":\n",
        "            if char == \"(\":\n",
        "                in_brackets += 1\n",
        "                current_param.append(char)\n",
        "            elif char == \")\":\n",
        "                in_brackets -= 1\n",
        "                current_param.append(char)\n",
        "            elif char == \",\" and in_brackets == 0:\n",
        "                param = \"\".join(current_param).strip()\n",
        "                if param:\n",
        "                    if \"=\" in param:\n",
        "                        key, value = param.split(\"=\", 1)\n",
        "                        key = key.strip()\n",
        "                        value = value.strip()\n",
        "                        try:\n",
        "                            param_dict[key] = ast.literal_eval(value)\n",
        "                        except:\n",
        "                            param_dict[key] = value\n",
        "                    else:\n",
        "                        param_dict[param] = None\n",
        "                current_param = []\n",
        "            else:\n",
        "                current_param.append(char)\n",
        "\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    # Обработка входных данных\n",
        "    lines = [line.strip() for line in model_str.splitlines() if line.strip()]\n",
        "    if not lines:\n",
        "        return {\"model_name\": \"Unknown\", \"layers\": []}\n",
        "\n",
        "    # Извлекаем имя модели из первой строки (новый способ)\n",
        "    model_name = lines[0].split(\"(\", 1)[0].strip()\n",
        "    model_dict = {\n",
        "        \"model_name\": model_name,\n",
        "        \"layers\": []\n",
        "    }\n",
        "\n",
        "    # Регулярное выражение для слоев\n",
        "    layer_pattern = re.compile(r\"\\((\\w+)\\):\\s*(\\w+)\\((.*)\\)\")\n",
        "\n",
        "    for line in lines[1:]:\n",
        "        if line.startswith(\"(\") and \"):\" in line:\n",
        "            match = layer_pattern.match(line)\n",
        "            if match:\n",
        "                layer_name, layer_type, params = match.groups()\n",
        "                try:\n",
        "                    layer_info = parse_layer(f\"{layer_type}({params})\")\n",
        "                    model_dict[\"layers\"].append({\n",
        "                        \"name\": layer_name,\n",
        "                        \"type\": layer_type,\n",
        "                        \"parameters\": layer_info[\"parameters\"]\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing layer {layer_name}: {str(e)}\")\n",
        "\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDthBDWeH9ah"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}